# ML Assignment 1 â€” BITS F464 Machine Learning

**Course:** BITS F464 | **Semester:** 1, 2025â€“26 | **Campus:** BITS Pilani, Hyderabad  
**Deadline:** March 1, 2026, 11:59 PM | **Demo:** Week of March 2, 2026

---

## Team Overview

| Person   | Module                     | % Done | Status         |
|----------|----------------------------|--------|----------------|
| Kartik   | Data & Utilities           | ~43%   | ğŸŸ¡ Partial     |
| Gursidak | EDA                        | ~75%   | ğŸŸ¡ Partial     |
| Tushya   | Linear Models              | ~30%   | ğŸ”µ In Progress |
| Jayesh   | Advanced Models            | 0%     | ğŸ”´ Not Started |

---

## Task 1 â€” Data Loading & Preprocessing *(Kartik)*

| Sub-task | Status |
|---|---|
| Load dataset; inspect shape & dtypes | âœ… Done |
| Identify missing values | âœ… Done |
| Define target variable (`Total_GHG_kgCO2e`) | âœ… Done |
| Explicit numerical vs categorical feature separation | âŒ Pending |
| Z-score normalisation (from scratch) | âš ï¸ Done by Tushya â€” see note below |
| 80/20 train-test split (from scratch) | âš ï¸ Done by Tushya â€” see note below |
| Shared metric helpers (`mae`, `mse`, `r2_score`) | âš ï¸ Done by Tushya â€” see note below |

> **Note for Kartik:** The three items marked âš ï¸ were implemented early by Tushya to unblock the linear models module (no sklearn â€” pure NumPy). Please wrap these into a reusable `get_data()` function so Jayesh's module can call it cleanly without copy-pasting.

---

## Task 2 â€” Exploratory Data Analysis *(Gursidak)*

| Sub-task | Status |
|---|---|
| Descriptive statistics (`df.describe()`) | âœ… Done |
| Histograms for all numerical features | âœ… Done |
| Boxplots + outlier analysis | âœ… Done |
| Correlation heatmap | âœ… Done |
| â‰¥3 insights in markdown | âœ… Done |
| Scatter plots â€” each feature vs `Total_GHG_kgCO2e` (Task 2c) | âŒ Missing |
| Bar chart of descriptive stats (min/max/mean/median/std) | âŒ Missing |

> **Note for Gursidak:** Two items are missing that the assignment explicitly requires. Add scatter plots (Task 2c) and the descriptive stats bar chart before final submission.

---

## Task 3 â€” Linear Regression *(Tushya)*

| Sub-task | Status |
|---|---|
| Feature selection + justification | âœ… Done |
| Z-score normalisation (from scratch) | âœ… Done |
| 80/20 train-test split (from scratch) | âœ… Done |
| Metric helpers: `mae()`, `mse()`, `r2_score()`, `denorm_y()` | âœ… Done |
| Batch Gradient Descent (BGD) â€” from scratch | âŒ Pending |
| SGD loss tracking per epoch | âŒ Pending |
| Stochastic Gradient Descent (SGD) â€” from scratch | âŒ Pending |
| BGD loss tracking per epoch | âŒ Pending |
| MAE / MSE / RÂ² evaluation on test set (original scale) | âŒ Pending |
| BGD vs SGD â€” loss curve comparison plot | âŒ Pending |
| BGD vs SGD â€” metrics comparison table + discussion | âŒ Pending |

---

## Task 4 â€” Polynomial Regression + Regularisation *(Jayesh)*

| Sub-task | Status |
|---|---|
| Polynomial features degree 2 (from scratch) | âŒ Pending |
| L1 Lasso regularisation | âŒ Pending |
| L2 Ridge regularisation | âŒ Pending |
| Evaluation & comparison with linear regression | âŒ Pending |
| Visualisations | âŒ Pending |

> **Dependency for Jayesh:** You can directly reuse the normalisation, split, and metric helper cells Tushya added (cells 15â€“18 in the notebook). No need to wait for Kartik's `get_data()` refactor to start.

---

## Task 5 â€” Classification Reformulation *(Jayesh)*

| Sub-task | Status |
|---|---|
| Labelling strategy (low / medium / high emissions) â€” justified | âŒ Pending |
| Logistic Regression (from scratch) | âŒ Pending |
| Naive Bayes (from scratch) | âŒ Pending |
| Perceptron (from scratch) | âŒ Pending |
| Accuracy, Precision, Recall, F1, Confusion Matrix | âŒ Pending |
| Visualisations + strengths/limitations discussion | âŒ Pending |

---

## Notes

- **No external ML libraries.** All algorithms must be implemented from scratch. Only NumPy, Pandas, Matplotlib, and Seaborn are permitted.
- Submission filename: `TeamXX_Assignment1.ipynb`
- Run the entire notebook end-to-end before submitting â€” all outputs must be visible.
